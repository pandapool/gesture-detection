# -*- coding: utf-8 -*-
"""gesture.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OwrufYgAVOz6zNpy35OQ6ihRAzP07gGw
"""
import os
import cv2
import math
import numpy as np
from tqdm import tqdm
from skimage import feature
import imutils
import itertools
import matplotlib.pyplot as plt
from IPython.display import clear_output
import json


from tensorflow.python import keras
from keras import layers
from keras.models import Model, Sequential
from keras.optimizers import Adam

from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelBinarizer


RANDOM_SEED = 123
np.random.seed(RANDOM_SEED)
plt.rcParams["figure.facecolor"] = "w"

alphabet = {str(i):i for i in range(0,6)}
NUM_CLASSES = len(alphabet)

def get_class_label(val):
    """
    Function returns the key (Letter: a/b/c/...) value from the Alphaber dictionary
    based on its class index (1/2/3/...)
    """
    for key, value in alphabet.items():
        if value == val:
            return key
        

def load_data(dir, img_size=200):
    """
    Load resized images as np.arrays to workspace
    """
    X = []
    y = []
    for path in tqdm(sorted(os.listdir(dir))):
        for file in os.listdir(dir + path):
            if not file.startswith('.'):
                img = cv2.imread(dir + path + '/' + file, 0)
                img = ~img
                img = cv2.GaussianBlur(img, (3, 3), 0)
                
                img = cv2.resize(img,dsize=(img_size, img_size),interpolation=cv2.INTER_CUBIC )
                
                X.append(img)
                y.append(alphabet[path])

    X = np.array(X)
    X = X.astype('float32')/255.0
    y = np.array(y)
    print('\n{} images loaded.'.format(len(X)))
    return X, y


IMG_SIZE = 200

TEST_DIR = 'c:/Users/hp/Desktop/my_dataset_edges/test/'
TRAIN_DIR = 'c:/Users/hp/Desktop/my_dataset_edges/train/'

X_train, y_train = load_data(TRAIN_DIR, IMG_SIZE)
X_test, y_test = load_data(TEST_DIR, IMG_SIZE)

print("first time : "+str(X_train.shape))
# transform
X_train = X_train.reshape(X_train.shape + (1,))
X_test = X_test.reshape(X_test.shape + (1,))


print("next time : "+str(X_train.shape))

label_binarizer = LabelBinarizer()
y_train_encoded = label_binarizer.fit_transform(y_train)
y_test_encoded = label_binarizer.fit_transform(y_test)

img_input = layers.Input(shape=(IMG_SIZE, IMG_SIZE,1))

x = layers.Conv2D(64, 2, activation='softmax',padding='same')(img_input)
x = layers.Conv2D(32, 2, activation='softmax',padding='same')(x)
x = layers.MaxPooling2D(2)(x)
x = layers.Dropout(0.1)(x)
x = layers.Conv2D(64, 2, activation='softmax',padding='same')(x)
x = layers.Conv2D(128, 3, activation='softmax',padding='same')(x)
x = layers.MaxPooling2D(2)(x)
x = layers.Dropout(0.1)(x)
x = layers.Conv2D(64, 2, activation='softmax',padding='same')(x)
x = layers.MaxPooling2D(2)(x)
x = layers.Flatten()(x)
x = layers.Dense(128, activation='softmax')(x)
x = layers.Dropout(0.1)(x)

output = layers.Dense(NUM_CLASSES, activation='relu')(x)

model = Model(img_input, output)
model.summary()

model.compile(loss='categorical_crossentropy',optimizer=Adam(1e-04),metrics=['acc'])

# lets assume `model` is main model 
model_json = model.to_json()
with open("model_in_json.json", "w") as json_file:
    json.dump(model_json, json_file)
"""
with open('model_in_json.json','r') as f:
    model_json = json.load(f)

model = model_from_json(model_json)
"""
EPOCHS = 15
BATCH_SIZE = 32

history = model.fit(
    x=X_train, 
    y=y_train_encoded,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(X_test, y_test_encoded)
)

"""score, acc = model.evaluate(X_test, y_test,batch_size=110)
print('Test score:', score)
print('Test accuracy:', acc)
"""

# validate
predictions = model.predict(X_test)
predictions = np.argmax(predictions, axis=1)

accuracy = accuracy_score(y_test, predictions)
print('Test Accuracy = %.2f' % accuracy)

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    
    plt.figure(figsize = (15,10))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=90)
    plt.yticks(tick_marks, classes)
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    thresh = cm.max() / 2.
    cm = np.round(cm,2)
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")
    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.show()

confusion_mtx = confusion_matrix(y_test, predictions) 
cm = plot_confusion_matrix(confusion_mtx, classes = list(alphabet.keys()), normalize=True)

model.save('model_weights.h5')

